# -*- coding: utf-8 -*-
"""Linguify Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z2jisTGMTQhtDfSfthxVoDbxfZOUUns8
"""

# Install required libraries

!pip install openai==0.28
!pip install transformers datasets nltk openai

# Import necessary libraries
from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments
from datasets import load_dataset, DatasetDict
import torch
import nltk
from nltk.translate.gleu_score import sentence_gleu
import openai

# Downloading NLTK data
nltk.download("punkt")

# Setting up OpenAI API key that is required for feedback generation
openai.api_key = 'insert_your_api_key'

# Loading the JFLEG dataset
dataset = load_dataset("jhu-clsp/jfleg")

# Splitting the dataset into train, validation, and test sets
train_test_split = dataset['validation'].train_test_split(test_size=0.2)
dataset = DatasetDict({
    'train': train_test_split['train'],
    'validation': train_test_split['test'],
    'test': dataset['test']
})

# Loading T5 model and tokenizer
model_name = "t5-base"
model = T5ForConditionalGeneration.from_pretrained(model_name).to("cuda")
tokenizer = T5Tokenizer.from_pretrained(model_name)

# Preprocessing data for model input
def preprocess_function(examples):
    inputs = ["fix: " + sentence for sentence in examples["sentence"]]
    targets = [correction[0] if correction else "" for correction in examples["corrections"]]
    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding="max_length")
    model_inputs["labels"] = tokenizer(text_target=targets, max_length=128, truncation=True, padding="max_length")["input_ids"]
    return model_inputs

# Tokenize the dataset
tokenized_datasets = dataset.map(preprocess_function, batched=True)

# Define training arguments
training_args = TrainingArguments(
    output_dir="./t5_finetuned_jfleg",
    evaluation_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=10,
    weight_decay=0.01,
    report_to="none"
)

# Initializing Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
)

# Fine-tuning the model
trainer.train()

# Function for grammar correction
def correct_grammar(test_data):
    corrected_sentences = []
    for sentence in test_data["sentence"]:
        input_text = f"fix: {sentence}"
        input_ids = tokenizer.encode(input_text, return_tensors="pt").to("cuda")
        outputs = model.generate(input_ids, max_length=64, num_beams=4, early_stopping=True)
        corrected_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)

        # Keeping original sentence if corrected output is empty
        corrected_sentence = corrected_sentence if corrected_sentence.strip() else sentence
        corrected_sentences.append(corrected_sentence)

        print(f"Original: {sentence}")
        print(f"Corrected: {corrected_sentence}")
        print("="*40)

    return corrected_sentences

# Function to evaluate GLEU score
def evaluate_gleu(corrected_sentences, test_data):
    gleu_scores = []
    for corrected_sentence, references in zip(corrected_sentences, test_data["corrections"]):
        prediction_tokens = corrected_sentence.split()
        reference_tokens = [ref.split() for ref in references]
        gleu_score = sentence_gleu(reference_tokens, prediction_tokens)
        gleu_scores.append(gleu_score)

    avg_gleu_score = sum(gleu_scores) / len(gleu_scores)
    print(f"\nAverage GLEU Score: {avg_gleu_score:.4f}")
    return avg_gleu_score

# Function to provide feedback using OpenAI API
def provide_feedback(sentences):
    for sentence in sentences[:10]:  # Automatically limits to the first 10 sentences
        prompt = f"The sentence is: '{sentence}'\n" \
                 f"Please provide detailed feedback on the grammatical correctness of this sentence and suggest improvements if necessary."
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a grammar expert."},
                {"role": "user", "content": prompt}
            ]
        )
        feedback = response['choices'][0]['message']['content']
        print(f"Feedback for: '{sentence}'\n{feedback}")
        print("="*80)

# Example usage with any list of sentences
sentences = [...]  # Replace with your full list of sentences

corrected_sentences = correct_grammar(tokenized_datasets["test"])

# Evaluating model based on GLEU score on the test set
evaluate_gleu(corrected_sentences, tokenized_datasets["test"])

provide_feedback(corrected_sentences)